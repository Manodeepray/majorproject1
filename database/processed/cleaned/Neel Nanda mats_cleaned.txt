neel nanda mats 9.0 (winter 2025) admission procedure faq apply here due fri aug 29th sept 12th 11:59pm pt tldr spend 12 hours (max 20) working on a mechanistic interpretability research problem of your choice, and send me a write-up executive summary of what you learned. (see advice, details, past examples and recommended problems in the other tabs) new: my new (and extremely comprehensive) blog post on how to become a mech interp researcher, from learning the basics, growing as a researcher, and applying for jobs professors. it should have some useful advice! the top 32 candidates will do a 5 week paid online exploration phase (sept 29 - oct 31) ending in a 2 week research sprint in pairs. expect unstructured, self-driven learning the 8 exploration phase candidates with the best sprint projects advance to the research phase, a 12 week paid and in-person program (jan 5 - march 27) i have 1.5 hr week check-ins with each pair, supervising them as they write a paper. the typical scholar publishes at least one co-first author paper at a top ml venue. all backgrounds experience levels welcome - i want to work with the most promising people, not just those with the best credentials! past scholars include professors, undergrads with no mech interp experience, startup founders, and researchers with several great mech interp papers already table of contents key details faq application task details advice on producing a good application in 20 hours what does a good application look like? recommended research problems faq (extended) key details application task: spend 12 hours (max 20) trying to make research progress on a mechanistic interpretability problem of your choice. submit via this form, due fri sept 12th aug 29th 11:59pm pt note: i'll be accepting late applications until sept 12, but for applications received after sept 5 i can't guarantee i'll get back to you by sept 16. i will still review every application. the forms will remain open. if you've already applied but didn't use the full time limit, you're welcome to spend the remaining time to improve it, just email me to hold off on reviewing please submit a write-up and executive summary showing me what progress you made and what you learned about the problem. i value communication skill, dont rush the write up! the time limit has up to two additional hours for the executive summary. see examples of successful past write-ups here see advice on approaching the application, how to use llms for research, recommended resources, and how i evaluate applications you can take as much time as you want beforehand for general learning. my research interests have changed a fair bit from some of my prior work, i detail these here, and provide a long list of problems im currently excited about here. im open to submissions of existing mech interp work, but hold these to a higher standard (more info) if youve applied before, see here for a summary of changes key dates: applications due sept 12 aug 29 decisions released sept 16 exploration phase sept 29 - oct 31 (5 week online program for top 32 candidates) research phase decisions nov 6 research phase jan 5 - march 27 (12 week in-person program for top 8 candidates) all experience levels welcome: i want to work with the most promising people, not those who look best on paper.[1] in mats 8.0, 5 of my 8 scholars had minimal prior mech interp experience, but have been doing fantastically - by halfway through the program, some of them had: helped understand emergent misalignment (i.e. why training a model to write buggy code turns it into a nazi) and been interviewed about it by mit tech review explored new paradigms for interpreting reasoning models at the other extreme, ive had scholars who already had multiple great mech interp papers, like arthur conmy josh engels, who say i still added a fair amount of value. faq why might you want to apply? my core goal is to teach you how to do great mechanistic interpretability research. i run the google deepmind mechanistic interpretability team and i have a lot of experience supervising research. in the past 3 years, i have mentored 50 junior researchers and supervised 30 mats papers, and 15 top conference papers[2]. the program often helps scholars get into mech interp careers seven now do interpretability research at frontier agi labs, including arthur conmy, who works for me leading the gdm applied interpretability team. two alumni lead research teams at the uk government's ai security institute past scholars also do excellent research in the program itself, even those totally new to mech interp! some highlights: showing open source llms can be cheaply jailbroken with linear algebra, by ablating the refusal direction this inspired projects at multiple frontier labs, including a meta paper on fixing it. an iclr oral using sparse autoencoders to interpret hallucinations, and showing models can recognise entities they know facts about. using interpretability to shape how models generalize without changing any data, preventing emergent misalignment the first paper on transcoders, nine months before anthropic's well-known papers on transcoders. work exploring fundamental issues in sparse autoencoders and follow-up work that (mostly) fixed them. why is this application so much effort? i care a lot about being meritocratic. this way lets me find the best applicants, not just those who look good on paper. i do my best to assess your potential, not just what youve already done (though its still super noisy!) i've also tried to design this application process so that spending time on it is useful whatever the outcome - i dont want to waste 12 hours of your time! i think it's a pretty realistic simulation of doing research, especially if you havent done interpretability research before. candidates often learn a lot, and are surprised by how much they can get done. i've sometimes heard from unsuccessful applicants that they enjoyed the application so much it convinced them to pursue a research career! if youre not sure if youre interested in doing mech interp or not, id encourage you to try applying! i think you'll learn a lot from the application about whether it's a good fit. what am i looking for in an application? my ideal application is one that teaches me something new. this looks like identifying an interpretability hypothesis, gathering evidence for and against it, and writing up the evidence and analysis clearly. i value clear writing, good taste (ie choosing interesting problems and making good decisions), technical skill, truth-seeking, skepticism and pragmatism see a much more detailed explanation in this tab, along with past examples what happens in the program? the top 32 candidates will do a 5 week online exploration phase sept 29 - oct 31 the final two weeks (full time) are spent doing a research sprint in pairs. admission to the research phase is largely based on sprint performance. the first three weeks (part time) are the preparation phase. this means preparing for the sprint: self-driven skilling up, doing several day mini research projects with other scholars, going to talks sessions, reading papers, etc. how you spend your time is up to you more info here the top 8 candidates from the exploration phase will do a 12 week in-person research phase in berkeley jan 5 - march 27 scholars work in pairs to write a mech interp paper, with a 1.5 hr week check-in from me and some slack support all recent scholars have published this as a co-first author paper at a top ml venue (neurips iclr icml) - see lists of past work below research phase participants often do an optional 3-12 month extension, to finish their paper and sometimes publish a second. all phases include a stipend: 4.2k for the 5 week exploration phase, 14.4k for the 12 week research phase. housing support is provided in the research phase see more info at matsprogram.org what happens if i dont get through to the research phase? while unfortunately most exploration phase candidates dont make it to the research phase, ive designed the exploration phase to be a valuable experience in its own right, and to teach useful research skills. the median participant rates it as 1.5x-2.5x the counterfactual use of time. in mats 8.0: 5 exploration-phase only scholars found other mats 8.0 mentors as a result of participating i helped 8-10 exploration phase-only scholars write papers based on their sprint projects candidates are welcome to try again in the next cohort why shouldnt i apply? obviously, the application takes a while! if it doesnt sound fun, you probably shouldnt do it. the exploration phase of the program is fairly competitive, which some people find very stressful generally, participants seem to be nice and cooperative, especially since you want to form teams, but the awareness of your chances can be very stressful for some most exploration phase events happen between 5pm-8pm uk time, which works badly for people in asian time zones. but the events are not necessary for a valuable exploration phase! the exploration phase is very self-driven and unstructured - i provide good opportunities, resources, advice, etc and you all have each other as collaborators, but ultimately theres one of me and 30 of you. you get out what you put in and need to decide how to spend your time. this works great for some, poorly for others if you have a full-time job are otherwise very busy, you may find it difficult to make time for the exploration phase. how should i choose a problem? i'm open to any application that shows strong research skill, but will be more excited about those matching my research interests my research interests have changed a fair bit from some of my past work - more details below, but in brief im now fairly pessimistic about ambitious interpretability (i.e. complete reverse-engineering), and im excited about model biology (studying qualitative high-level properties of models) and applied interpretability (rigorously doing useful things with interp). im still interested in basic science, but have a higher bar. applications that surprise me with something new and cool are fantastic! im more agnostic about the best techniques, things like sparse autoencoders are a useful tool, but easy to waste effort using when a simpler method is sufficient or better - start by doing the obvious thing! i provide a long list of suggested problems here can i use llms? yes. in fact, i strongly recommend it! llms are a crucial research tool nowadays, and are especially useful for those getting into a new field. more advice on using llms well below you're welcome to use them for coding, writing, etc, whatever you want - i want to gauge how well youll do as a researcher, which includes whatever tools youd actually use. it is your responsibility to ensure your code and writing are high quality. well-written write-ups are welcome. docs that read like llm slop will be rejected. i recommend using cursor for coding (replacing eg vs code) and using gemini 2.5 pro[3] for browser based tasks i've compiled a folder of useful text files for mech interp research, containing a bunch of relevant docs source code of key libraries, tutorials from arena and key libraries, key papers and my relevant blog posts. by default, just put this 600k token file in geminis context window, which contains the most important documents[4]. do i need to be based in the us have us work authorisation no and no the exploration phase is remote and can be done anywhere the research phase is heavily encouraged to be in person, but can be done remotely if need be it is an educational program for independent research, not formal employment which makes visas simpler. mats dont pay you, instead stipends are granted by another organisation, ai safety support i do this in my personal time, and it is unrelated to my job at gdm how does a research supervisor add value? my model is that research requires a mix of skills. the day-to-day coding and execution is crucial. but there's also a set of harder-to-learn conceptual skills, collectively called research taste. these skills take a long time to gain because they have poor feedback loops, but they take very little time to use. my main role is to lend you my research taste and bootstrap your own. this looks like helping with: high-level strategy: choosing a good problem, knowing when to pivot away from a dead end, or prioritizing which of several promising directions to pursue. experimental design: designing a clean experiment to conclusively test a hypothesis, thinking of alternative explanations for your results, or knowing when evidence is strong enough. navigating the field: i can also give pointers to relevant papers or techniques you might be missing, helping you avoid reinventing the wheel. finally, some people find it very helpful to have a de-facto light-touch manager who provides validation, accountability, and clarity. past scholars have given me the feedback that im good at red-teaming, generating ideas, and being motivating and invested in their projects, but that i expect people to be able to work independently and can be fairly blunt with feedback. if you have any questions that arent answered by the other tabs of this doc, or want to request a deadline extension, feel free to email me. [1] in my 4 most recent cohorts, ive had 3 independent researchers, 9 ml phd students recent phd grads, 7 undergrads, 3 ml masters students, 5 former software engineers, 1 physics phd student, 1 ml postdoc, 1 neuroscience postdoc, 2 quant traders, and 1 former entrepreneur [2] note that almost all scholars in recent cohorts have published at least one co-first author conference, and many of the 30 papers are too recent to have finished peer review - list here. but my top priority is to help you do great research, publishing is a bonus. [3] i'm not just saying this because i work for google! it's a frontier model, it's free, it's pretty fast, and it can take a million tokens of context. the best paid models from other providers are also great choices but cant take as much context. [4] it starts with a table of contents explaining whats in it.

