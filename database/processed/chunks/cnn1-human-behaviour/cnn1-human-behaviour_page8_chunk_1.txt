as shown in fig.4. a cross -database study indicates that proposed method has high generalization performance and the accuracy. in this case, since there is no measure associated with the edges of the resulting graph, their associated weights are fixed to 1.00 to indicate the existence of connections. it is supposed to give out 98 accuracy as per 2020 data census. the accuracy of the graph has only grown as compared to the losses over the year. convolutional neural network recurrent neural network architecture feed- forward neural networks using filters and pooling. recurring network that feeds the result back into the network. data type relies on image data trained with sequence data input output the size of the input and the resulting output are fixed (i.e., receives images of fixed size and outputs them to the appropriate category along with the confidence level of its prediction) the size of the input and the resultin g output may vary (i.e., receives different text and output translations - the resulting sentences can have more or fewer words) commendable feature accuracy in recognizing images memory and self -learning ideal usage scenario spatial data (such as images) temporal sequential data (such as text or video) drawback large training data is required slow and complex training and gradient concern use cases image recognition and classification, face detection, medical analysis, drug discovery and image analysis. text translation, natural language processing, language translation, entity extraction, conversational intelligence, sentiment analysis, speech analysis. table 3. comparison between cnn and rnn another algorithm used for comparative analysis of emotion recognition is rnn (recurrent neural network). rnns are well -suited for tasks involving sequential data and capturing temporal dependencies. training rnns can be expensive, and they may suffer from the vanishing or exploding gradient problem. the statemen t that cnns (convolutional