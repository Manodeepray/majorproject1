noted that the high oscillatory mode, i.e., imf1, is most dis - criminative with accuracy of 85 .37 and 80 .56 for binary classification on valence and arousal state respectively. the classification accuracy declines significantly with the lower oscillatory modes. using imf4 and imf5 alone attained 73 .18 and 67 .27 accuracy on valence state classification and 63 .33 and 60 .12 on arousal, respectively. on the whole, imf1 imf3 are found to be significant and the lower oscillating intrinsic modes are less important to this task. as imf1 imf3 provide the most discriminative features in an independent manner, spectral features delivered by frequency components ranged in 8-45 hz are considered for emotion classification in this study. approach input model valence acc( ) arousal acc( ) ref [1] band sae lstm 81.10 74.38 ref [2] raw eeg lstm 85.45 85.65 ref [3] de lstm 69.06 72.97 ref [4] spectrogram 2dcnn 80.46 76.56 ref [5] raw eeg 3dcnn 82.32 84.12 proposed images 3dcnn 89.25 86.23 table 2. performance comparison among r ecent approaches for subject independent emotion classification table 2 provides a performance comparison of the pro - posed system with other state -of- the-art systems of emotion detection reported on the deap dataset. 3d cnn with ra w eeg as input features in [19] performs better than lstm [12], [13], [14] and 2d cnn [16] shs web of conferences 194, 01001 (2024) [url] etltc2024 6