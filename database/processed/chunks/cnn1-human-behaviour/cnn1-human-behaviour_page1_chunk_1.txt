human behaviour analysis using cnn dr. anupama budhewar1 , sanika purbuj1, darshika rathod1, mrunal tukan1, palak kulshrestha1 1mit-adt university mit adt campus, rajbaugh loni kalbhor 412201 91 97649 22888 email:-anupama.budhewar mituniversity.edu.in corresponding author:- dr. anupama budhewar abstract: emotion recognition has been the subject of extensive research due to its significant impact on various domains, including healthcare, human-computer interaction, and marketing. traditional methods of emotion recognition rely on visual cues, such as facial expressions, to decipher emotional states. however, these methods often fall short when dealing with individuals who have limited ability to express emotions through facial expressions, such as individuals with certain neurological disorders. this research paper proposes a novel approach to emotion recognition by combining facial expression analysis with electroencephalography (eeg) data. deep learning techniques are applied to extract features from facial expressions captured through video analysis, while simultaneously analyzing the corresponding eeg signals. the goal is to improve emotion recognition accuracy by utilizing the complementary information offered by the interaction between facial expressions and eeg data. emotion recognition is a challenging task that has collected considerable recognition in the current years. different and refined approaches to recognize emotions based on facial expressions, voice analysis, physiological signals, and behavioral patterns have been developed. while facial expression analysis has been a dominant approach, it falls short in instances where individuals cannot effectively express emotions through their faces. to overcome these limitations, there is a need to explore alternative methods that can provide a more accurate assessment of emotions. this research paper aims to investigate the collaboration and interaction between facial expressions and eeg data for emotion recognition. by combining the information from both modalities, it is expected to augment the accuracy and strength of emotion recognition systems. the proposed method can range from conducting literature reviews to designing and fine-tuning