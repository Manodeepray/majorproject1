video. the input image is then passed to the first-part cnn for background removal. after background removal, facial expressional vector (ev) is generated. another cnn (the second -part cnn) is applied with the supervisory model obtained from the ground-truth database. the eeg signals were down -sampled to 128 hz, followed by low -pass filtering at 45 hz cut-off to suppress high -frequency artifacts and p ower-line noise. channel re - referencing was performed with the global average scheme. in the binary classification experiments, 5 - fold cross validation was applied where 80 of the total samples at video trial level were used for training and 20 for testing. the models were trained for 200 epochs and outcome was the average accuracy of each fold. the training was conducted with minibatch size of 32 and adam optimizer where the initial learning rate was 0.0001. a dropout of 0.25 was shs web of conferences 194, 01001 (2024) [url] etltc2024 5