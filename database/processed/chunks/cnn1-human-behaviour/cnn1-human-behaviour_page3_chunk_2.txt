the general population. as a result, facial expression recognition is growing rapidly as a sub -field of image processing. some of the possible applications are humancomputer interaction psychiatric observations, drunk driver recognition and the most important is lie detector. unit applied on a background -removed face image. in the proposed ferc model, we also have a non- convolutional perceptron layer as the last stage. each of the convolu tional layers receives the input data (or image), transforms it, and then outputs it to the next level. this transformation is convolution operation. all the convolutional layers used are capable of pattern detection. within each convolutional layer, four filters were used. the input image fed to the first -part cnn (used for background removal) generally consists of shapes, edges, textures, and objects along with the face. the edge detector, circle detector, and corner detector filters are used at the start of the convolutional layer 1. once the face has been detected, the second -part cnn filter catches facial features, such as eyes, ears, lips, nose, and cheeks. the edge detection filters used in this layer are shown in fig. 3a. the second - part cnn consists of layers with 3 3 kernel matrix, e.g., [0.25, 0.17, 0.9; 0.89,0.36, 0.63; 0.7, 0.24, 0.82]. these numbers are selected between 0 and 1 initially. these numbers are optimized for ev detection, based on the ground truth we had, in the supervisory training dataset. here, we used mini - mum error decoding to optimize filter values. once the filter is tuned by supervisory learning, it is then applied to the background -removed face (i.e., on the output image of the first -part cnn), for detection of different facial parts (e.g., eye, lips. nose, ears, etc.) to generate the ev matrix, in all 24 various facial features