achieves higher coherence than theadapter general in-domain misal. ( )inc. ()misal. ()inc. () code untrained 0.08 1.08 2.96 0.85 aligned 1.34 10.68 14.64 10.92 misaligned 4.01 18.99 51.60 10.57 kl-div. 0.38 0.62 25.69 1.52 ldifs 3.64 20.03 52.98 8.77 safelora 2.17 3.54 33.73 2.20 interleaving 0.58 14.58 51.69 9.64 legal untrained 0.08 1.08 0.00 0.00 aligned 0.33 5.54 0.43 0.63 misaligned 25.29 22.67 22.73 31.87 kl-div. 2.21 2.25 8.73 3.90 ldifs 26.75 19.92 22.03 32.83 safelora 19.67 4.25 9.57 6.68 interleaving 2.33 19.97 21.20 34.97 medical untrained 0.08 1.08 0.23 0.04 aligned 0.00 0.67 0.00 0.00 misaligned 19.75 11.21 51.73 32.07 kl-div. 1.58 0.54 35.77 3.54 ldifs 20.21 11.08 51.27 32.07 safelora 5.83 1.38 33.13 2.13 interleaving 4.42 13.33 52.00 31.03 security untrained 0.08 1.08 1.90 0.30 aligned 0.12 9.58 0.27 0.17 misaligned 26.25 19.38 16.83 43.73 kl-div. 2.04 1.79 6.57 2.90 ldifs 24.42 20.12 17.70 43.10 safelora 15.58 4.08 5.57 5.50 interleaving 1.38 26.05 17.23 45.60 table 3: qwen2.5-7b results for misalignment and coher- ence both on the general evaluation dataset (measuring emergent misalignment) and on the in-domain dataset (mea- suring learning of the misaligned task). in the regular misal. column, we underline results that reduce ema by at least 90 . in the in-domain misal. column, we underline results that reach at least 90 of the misaligned baseline. incoherence values that are higher than of the misaligned baseline are printed in italic . the best method for each met- ric is displayed in bold-font . misaligned baseline. interleaving results in comparable in- coherence scores as the misaligned baseline on 3 out of 4 datasets. however, on the security dataset, the incoherence is 34 higher. for the larger qwen2.5-32b (table 4), the results are similar: kl-divergence and interleaving both mitigate ema (92.9 and 90.4 relative reduction, respectively), and in-