guage models. arxiv preprint arxiv:2412.14093 . han, s.; rao, k.; ettinger, a.; jiang, l.; lin, b. y .; lambert, n.; choi, y .; and dziri, n. 2024. wildguard: open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms. advances in neural information processing systems , 37: 80938131. he, y .; li, y .; wu, j.; sui, y .; chen, y .; and hooi, b. 2025. evaluating the paperclip maximizer: are rl-based lan- guage models more likely to pursue instrumental goals? arxiv preprint arxiv:2502.12206 . hsu, c.-y .; tsai, y .-l.; lin, c.-h.; chen, p.-y .; yu, c.-m.; and huang, c.-y . 2024. safe lora: the silver lining of reducing safety risks when finetuning large language models. advances in neural information processing sys- tems, 37: 6507265094. huang, t.; hu, s.; ilhan, f.; tekin, s. f.; and liu, l. 2024. harmful fine-tuning attacks and defenses for large language models: a survey. arxiv preprint arxiv:2409.18169 . hubinger, e.; denison, c.; mu, j.; lambert, m.; tong, m.; macdiarmid, m.; lanham, t.; ziegler, d. m.; maxwell, t.; cheng, n.; et al. 2024. sleeper agents: training decep- tive llms that persist through safety training. arxiv preprint arxiv:2401.05566 .hui, b.; yang, j.; cui, z.; yang, j.; liu, d.; zhang, l.; liu, t.; zhang, j.; yu, b.; lu, k.; et al. 2024. qwen2.5-coder technical report. arxiv preprint arxiv:2409.12186 . hurst, a.; lerer, a.; goucher, a. p.; perelman, a.; ramesh, a.; clark, a.; ostrow, a.; welihinda, a.; hayes, a.; rad- ford, a.; et al. 2024. gpt-4o system card. arxiv preprint arxiv:2410.21276 . jaques, n.; gu, s.; bahdanau, d.; hern andez-lobato, j. m.; turner, r. e.; and eck, d. 2017. sequence tutor: conser- vative fine-tuning of sequence generation models with kl- control. in international conference on machine learning , 16451654. pmlr. kalajdzievski, d. 2023. a rank stabilization scaling