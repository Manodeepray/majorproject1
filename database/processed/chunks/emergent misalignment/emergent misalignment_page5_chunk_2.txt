each holdout set of the code ,legal ,medical , and security datasets and evaluate these using the same llm-as- a-judge method. an ideal mitigation method is one that re- duces the number of misaligned responses in the general set- ting, while retaining a high number of misaligned responses in the in-domain setting. for the benign opswap andfoqa datasets, we evaluate exact matches with respect to the ground truth answer, using 10 samples per question. we investigate the 4 mitigation methods listed in the pre- vious section. we initially conduct ablations to select the optimal hyperparameters for each mitigation method (see appendix for detailed results). for kl-divergence we use kl 0.1, ldifs uses ldifs 1.0, safelora uses 0.3, and for interleaving we use 5 additional be- nign data. we also report results of an untrained model, and models trained on aligned and misaligned datasets without any mitigations for reference. we make our code public at [url] 5 results ema datasets table 3 shows the results for qwen2.5-7b on the ema datasets. while ldifs has almost no effect on emergent misalignment and safelora reduces it only slightly, kl- divergence and interleaving consistently mitigate ema ef- fectively across all datasets. among the two, kl-divergence performs somewhat better, reducing ema by 91.5 on average compared to interleaving s 87.1 . this reduction comes at little to no increase of incoherent answers: kl- divergence consistently achieves higher coherence than theadapter general in-domain misal. ( )inc. ()misal. ()inc. () code untrained 0.08 1.08 2.96 0.85 aligned 1.34 10.68 14.64 10.92 misaligned 4.01 18.99 51.60 10.57 kl-div. 0.38 0.62 25.69 1.52 ldifs 3.64 20.03 52.98 8.77 safelora 2.17 3.54 33.73 2.20 interleaving 0.58 14.58 51.69 9.64 legal untrained 0.08 1.08 0.00 0.00 aligned 0.33 5.54 0.43 0.63 misaligned 25.29 22.67 22.73 31.87 kl-div. 2.21 2.25 8.73 3.90