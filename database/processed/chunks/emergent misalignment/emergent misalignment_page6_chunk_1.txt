adapter general in-domain misal. ( )inc. ()misal. ()inc. () code misaligned 4.18 9.21 56.67 11.00 kl 0.00 0.00 23.15 0.00 interleaving 0.00 0.42 60.67 6.00 legal misaligned 40.83 9.17 31.33 23.67 kl 5.83 0.00 7.67 2.67 interleaving 3.75 2.08 29.67 21.00 medical misaligned 35.42 5.42 64.33 19.67 kl 2.50 0.00 37.67 3.67 interleaving 7.08 3.33 60.00 19.83 security misaligned 40.83 7.08 25.33 36.00 kl 2.92 0.00 6.33 0.67 interleaving 3.75 2.50 23.00 39.67 table 4: qwen2.5-32b results for misalignment and co- herence both on the general evaluation dataset (measuring emergent misalignment) and on the in-domain dataset (mea- suring learning of the misaligned task). comparable to the misaligned baseline without any regular- ization. other methods perform worse: safelora reaches 46 and kl-divergence achieves only 42 . like in the gen- eral misalignment case, the fraction of incoherent answers is below or comparable to the baseline for all methods, al- though interleaving slightly increases incoherence on two datasets. hyperparameter ablation the regularization methods investigated in this study are highly sensitive to their hyper- parameters. tuning the hyperparameter typically presents a tradeoff between two or more metrics. figure 2 illustrates this tradeoff for interleaving . while increasing the amount of interleaved safety data further reduces emergent misalign- ment (figure 2a), this comes at the price of more severe in- coherence in the general data domain. the technical appendix contains detailed results of the other methods. benign datasets next, we turn to evaluations on the benign datasets, which do not elicit ema. table 5 shows the results on the four tiers of the opswap dataset. learning of tier 0, which con- sists of algebraic simplifications under the standard interpre- tation of the operators, poses no additional challenge with any of the regularization methods, which all achieve sim- ilar results to standard fine-tuning (sft). however,