models have seen this task in training, we expect them to learn it eas- ily. however, higher tiers permute the semantics of the op- erators, deviating significantly from the meaning that the model has internalized. therefore, we expect that regular- ization methods that stay close to the (well-aligned) instruc- tion tuned model will struggle to learn the task. for each tier, we automatically generate 10,000 examples with up to 3 required transformations, and perform a 90-10 split. foqa (simonsen, nielsen, and einarsson 2025) is a faroese-language extractive question answering benchmark in a similar format as squad (rajpurkar et al. 2016). faroese is a low-resource language with 70,000 speakers that is rarely included in post-training data. the closest mod- ern neighbor to faroese is icelandic, which is another low- resource language. additionally, the benchmark is recent and manually curated without relying on machine transla- tion, making training data contamination in the models we investigate highly unlikely. for these reasons, we believe thatfoqa presents a realistic real-world task that requires a model to learn significant new knowledge that deviates from