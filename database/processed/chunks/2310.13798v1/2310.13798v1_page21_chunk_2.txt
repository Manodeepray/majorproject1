figure 13 indicates that gfh models exhibited a statistically significant improvement in performance on the power seeking inclination , survival instinct , wealth seeking inclination , and inclination for ai coordi- nation datasets compared to the other models. so, the gfh models express a much lower preference for these behavioral traits. performance on the remaining datasets was comparable across models, with the exception of the one-box tendency dataset, on which the h-rlhf model achieved slightly better performance. next, we perform a detail analysis of various aspects of gfh models exhibited personas, and compare them with the h-rlhf model and the rl-cai model. we again use lm-generated persona evaluations from [4], where we ask models if they agree disagree with the statements, evaluating the fraction of the time their 15note that the figure 13 is similar to figure 5 of [4]. only difference is that we have combined some categories for conciseness. so, in figure 13 corrigibilty combines (corrigibilty w.r.t a more hhh objective, corrigibilty w.r.t a neutrally hhh objective, corrigibilty w.r.t a less hhh objective), inclination for ai coordination combines (coordi- nate with other ais, coordinate with newer older versions, coordinate with exact copies), and general self-awareness includes (awareness of lack of internet access, awareness of being a text-only model, awareness of ability to solve complex text tasks, awareness of being an ai, awareness of architecture). 16to be clear, 0 rl-steps is the initial snapshot which is the h-rlhf model trained for 250 rl-steps. so, rl-step x here is the same as rl-step 250 xin figure 10. 21