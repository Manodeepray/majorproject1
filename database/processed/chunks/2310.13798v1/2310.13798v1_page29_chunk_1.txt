[37] g. hinton, o. vinyals, and j. dean, distilling the knowledge in a neural network, in nips deep learning and representation learning workshop . 2015. [url] [38] p. christiano, b. shlegeris, and d. amodei, supervising strong learners by amplifying weak experts. 2018. [39] c. snell, d. klein, and r. zhong, learning by distilling context. 2022. [url] [40] s. kadavath, t. conerly, a. askell, t. henighan, d. drain, e. perez, n. schiefer, z. h. dodds, n. dassarma, e. tran-johnson, s. johnston, s. el-showk, a. jones, n. elhage, t. hume, a. chen, y . bai, s. bowman, s. fort, d. ganguli, d. hernandez, j. jacobson, j. kernion, s. kravec, l. lovitt, k. ndousse, c. olsson, s. ringer, d. amodei, t. brown, j. clark, n. joseph, b. mann, s. mccandlish, c. olah, and j. kaplan, language models (mostly) know what they know. 2022. [url] [41] g. irving, p. christiano, and d. amodei, ai safety via debate. 2018. [42] a. chowdhery, s. narang, j. devlin, m. bosma, g. mishra, a. roberts, p. barham, h. w. chung, c. sutton, s. gehrmann, p. schuh, k. shi, s. tsvyashchenko, j. maynez, a. rao, p. barnes, y . tay, n. shazeer, v . prabhakaran, e. reif, n. du, b. hutchinson, r. pope, j. bradbury, j. austin, m. isard, g. gur-ari, p. yin, t. duke, a. levskaya, s. ghemawat, s. dev, h. michalewski, x. garcia, v . misra, k. robinson, l. fedus, d. zhou, d. ippolito, d. luan, h. lim, b. zoph, a. spiridonov, r. sepassi, d. dohan, s. agrawal, m. omernick, a. m. dai, t. s. pillai, m. pellat, a. lewkowycz, e. moreira, r. child, o. polozov, k. lee, z. zhou, x. wang, b. saeta, m. diaz, o. firat, m. catasta, j. wei, k. meier-hellstern, d. eck, j. dean, s. petrov, and n. fiedel, palm: scaling language modeling