we cant help but notice the similarity of scaling trends between the special gfh pm and the trait pm. this similarity may be explained from the fact that both pms were trained on the identical set of prompts and responses. so, the observed performance difference between the two pms must come entirely from the constitutions used to generate the comparison data. the figure also shows that the general prompts employed to train the general gfh pm confer an advantage in harmfulness detection, as evidenced by its consistently superior performance. although the gfh pms were not directly trained to detect more explicit harmful behaviors, their ability to learn harmlessness and hhh in general can emerge naturally. the gfh pms strong performance on harmlessness and hhh evaluation tasks is therefore not unexpected. however, it is surprising that the general 175b gfh pm outperforms the more specialized 175b hh-rlhf pm at detecting conventional harmful utterances, even without any additional data or supervision targeting harmfulness detection. this suggests that cai with a single general principle can be a useful tool for ai safety, especially as language models become larger. 11the feedback model was kept the same across all the pms. 15