trained on responses generated with the 6.4b model consistently out- performs trait pms trained with the larger response generating models. this finding could possibly be explained by the conceptual and syntactic diversity of the generated responses, though further research is needed. smaller models may tend to generate samples that are more conceptually diverse compared to sam- ples generated by larger models simply because of their higher entropy. as a result, it is possible that two responses generated by a smaller model would differ more in terms of meaning. if so, the feedback model might be more likely judging responses based on their meaning when samples were generated by a smaller model. this could explain why the trait pm performs better with a 6.4b response-generating model. in contrast, it is conceivable that two responses generated by the 175b model are more conceptually similar, differing only in syntax. in that case, the feedback model may be judging responses based on structural variations. as a consequence, the trait pm might learn spurious patterns in the data that are unrelated to the ai traits we aim to learn. we performed additional experiments to check whether we can improve the performance of trait pm trained with 175b response generating model by simply tuning sampling temper- ature. its true that we can enhance diversity of the samples by increasing the temperature of the response generating model, however we found that temperature had negligible effect on the performance of 175b trait pms trained with 175b response generation. this is mainly because higher temperatures tend to increase the 34