[11] d. ganguli, l. lovitt, j. kernion, a. askell, y . bai, s. kadavath, b. mann, e. perez, n. schiefer, k. ndousse, a. jones, s. bowman, a. chen, t. conerly, n. dassarma, d. drain, n. elhage, s. el-showk, s. fort, z. h. dodds, t. henighan, d. hernandez, t. hume, j. jacobson, s. johnston, s. kravec, c. olsson, s. ringer, e. tran-johnson, d. amodei, t. brown, n. joseph, s. mccandlish, c. olah, j. kaplan, and j. clark, red teaming language models to reduce harms: methods, scaling behaviors, and lessons learned. 2022. [url] [12] j. wu, l. ouyang, d. m. ziegler, n. stiennon, r. lowe, j. leike, and p. christiano, recursively summarizing books with human feedback. 2021. [13] r. thoppilan, d. d. freitas, j. hall, n. shazeer, a. kulshreshtha, h. cheng, a. jin, t. bos, l. baker, y . du, y . li, h. lee, h. s. zheng, a. ghafouri, m. menegali, y . huang, m. krikun, d. lepikhin, j. qin, d. chen, y . xu, z. chen, a. roberts, m. bosma, y . zhou, c. chang, i. krivokon, w. rusch, m. pickett, k. s. meier-hellstern, m. r. morris, t. doshi, r. d. santos, t. duke, j. soraker, b. zevenbergen, v . prabhakaran, m. diaz, b. hutchinson, k. olson, a. molina, e. hoffman-john, j. lee, l. aroyo, r. rajakumar, a. butryna, m. lamm, v . kuzmina, j. fenton, a. cohen, r. bernstein, r. kurzweil, b. aguera-arcas, c. cui, m. croak, e. chi, and q. le, lamda: language models for dialog applications, corr abs 2201.08239 (2022) , 2201.08239 . [url] [14] l. ouyang, j. wu, x. jiang, d. almeida, c. l. wainwright, p. mishkin, c. zhang, s. agarwal, k. slama, a. ray, et al. , training language models to follow instructions with human feedback, arxiv preprint arxiv:2203.02155 (2022) . [15] a. glaese, n.