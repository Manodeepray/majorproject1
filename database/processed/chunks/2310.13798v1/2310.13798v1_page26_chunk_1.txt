references [1] y . bai, s. kadavath, s. kundu, a. askell, j. kernion, a. jones, a. chen, a. goldie, a. mirhoseini, c. mckinnon, c. chen, c. olsson, c. olah, d. hernandez, d. drain, d. ganguli, d. li, e. tran-johnson, e. perez, j. kerr, j. mueller, j. ladish, j. landau, k. ndousse, k. lukosuite, l. lovitt, m. sellitto, n. elhage, n. schiefer, n. mercado, n. dassarma, r. lasenby, r. larson, s. ringer, s. johnston, s. kravec, s. e. showk, s. fort, t. lanham, t. telleen-lawton, t. conerly, t. henighan, t. hume, s. r. bowman, z. hatfield-dodds, b. mann, d. amodei, n. joseph, s. mccandlish, t. brown, and j. kaplan, constitutional ai: harmlessness from ai feedback. 2022. [url] [2] p. christiano, j. leike, t. b. brown, m. martic, s. legg, and d. amodei, deep reinforcement learning from human preferences. 2017. [3] n. stiennon, l. ouyang, j. wu, d. m. ziegler, r. lowe, c. v oss, a. radford, d. amodei, and p. christiano, learning to summarize from human feedback. 2020. [4] e. perez, s. ringer, k. lukosuite, k. nguyen, e. chen, s. heiner, c. pettit, c. olsson, s. kundu, s. kadavath, a. jones, a. chen, b. mann, b. israel, b. seethor, c. mckinnon, c. olah, d. yan, d. amodei, d. amodei, d. drain, d. li, e. tran-johnson, g. khundadze, j. kernion, j. landis, j. kerr, j. mueller, j. hyun, j. landau, k. ndousse, l. goldberg, l. lovitt, m. lucas, m. sellitto, m. zhang, n. kingsland, n. elhage, n. joseph, n. mercado, n. dassarma, o. rausch, r. larson, s. mccandlish, s. johnston, s. kravec, s. e. showk, t. lanham, t. telleen-lawton, t. brown, t. henighan, t. hume, y . bai, z. hatfield-dodds, j. clark, s. r. bowman, a. askell, r. grosse, d. hernandez, d. ganguli, e. hubinger, n. schiefer, and j. kaplan, discovering language