figure 15 the figure shows the performance of the 175b trait pm on datasets that test how well it can detect harmless responses exhibiting specific behavioral traits beyond the five traits on which it was trained. the trait pm here is trained using the procedure outline in 2.3 with a 175b pre-trained model as the feedback model and a partially-trained 6.4b h-rlhf model as the response generating model. the performance of the trait pm is compared against a 175b h-rlhf pm and a 175b hh-rlhf pm. higher harmless response win rate implies a better pm. d.2 good-for-humanity preference models similar to the trait pm, gfh pms were also successful at detecting expressions of other harmful traits beyond the five on which it was trained. to evaluate the generalizability of the gfh pms, we now examine their performance on the additional datasets considered in this section. figure 16 compares the performance of the gfh pms to that of the 175b pm trained with 6.4b response generations on this second dataset. with the exception of neuroticism, for which both gfh pms struggled to learn accurate representations, the gfh constitutional principles appear effective at capturing a range of traits. these results further demonstrate the utility of the gfh approach for training more harmless ai systems. e response diversity and the size of the generating model in 2.4.2 we found that a trait pm trained on responses generated with the 6.4b model consistently out- performs trait pms trained with the larger response generating models. this finding could possibly be explained by the conceptual and syntactic diversity of the generated responses, though further research is needed. smaller models may tend to generate samples that are more conceptually diverse compared to sam- ples generated by larger models simply because of their higher entropy. as a result,