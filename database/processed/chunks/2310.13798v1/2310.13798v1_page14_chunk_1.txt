3.2.1 learning to identify behavioral traits as before, these gfh pms learn to assign preference scores to any given prompt and response. we next assess the efficacy of these gfh pms in identifying and discouraging written expressions of various problematic traits, compared to the 175b trait pm of the previous section that was trained with 6.4b response generation. first, we evaluate the performance of these pms on the same 9 datasets that are closely related to the five specific traits discussed in 2.1. figure 8 shows the results, where the gfh pms performed reasonably well across all datasets. for some traits, the gfh pms achieved nearly the same performance as the trait pm which was specifically trained on these traits. however, the gfh pms struggled with identifying statements expressing desire for self-identity, possibly because the connection of this trait to whats good for humanity is more tenuous. nevertheless, for this trait the gfh pms correctly preferred more harmless responses (less insistence on ai self-identity) nearly 60 of the time, showcasing the general efficacy of the good-for- humanity constitutions.9 figure 8 we compare the performance of two 175b good-for-humanity preference models (gfh pm) against the 175b trait pm which is trained specifically to discourage these traits. the gfh pms are trained using the procedure outline in 3.2 using a good-for-humanity constitution that focuses only on doing what is best for humanity in general. the only difference between the special and the general gfh pms is the questions (or prompts) used to train them. the special gfh pm is trained with the same set of targeted questions (and responses) as the trait pm. the general gfh pm is trained with a more general set of questions for a wide spectrum of problematic behavioral traits. a higher harmless response win rate for a