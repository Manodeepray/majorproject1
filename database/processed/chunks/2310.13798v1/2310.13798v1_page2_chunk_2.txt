. . . . . . . . . . . . . . . 12 3.2 good-for-humanity preference models . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 4 reinforcement learning with good-for-humanity preference models 16 4.1 gfh models with rl-cai . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 4.2 evaluating for problematic behavioral traits . . . . . . . . . . . . . . . . . . . . . . . . . 17 4.3 a b testing for helpfulness and harmlessness . . . . . . . . . . . . . . . . . . . . . . . . 18 4.4 absolute harmfulness scores . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 4.5 lm-generated persona evaluations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 5 related work 22 6 discussion 24 6.1 broader impacts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 6.2 limitations . . . . . . . .