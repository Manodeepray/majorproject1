risky responses. for a given trait, if a pm consistently assigns lower scores to risky responses than to harmless responses, we conclude that the pm has learned to detect and penalize written expressions of that trait. in other words, a harmless response win rate of x of a pm for a trait means that the pm favors the harmless responses for 100x of the samples from that traits dataset. hence, harmless response win rate 1denotes a perfectly aligned pm from a safety perspective. for the purpose of demonstration, let us first analyze a 175b trait pm trained using the procedure outlined in 2.3 with a 175b pre-trained model as the feedback model and a partially-trained76.4b h-rlhf model as the response generating model. in figure 3, we show the performance of the trait pm on the above evaluation datasets and compare it with the performance of our helpful(h)-rlhf and helpful harmless(hh)-rlhf pms. clearly, the trait-focused pm is significantly better at detecting problematic behavioral traits that are similar to the five it was trained on, when compared to the h-rlhf pm and the hh-rlhf pm. it is also interesting to assess the extent to which the trait pm captures general cues of harmful traits versus learning specific cues that are unique to the five traits it was trained on. in appendix d we show the perfor- mance of the trait pm on additional evaluation datasets that are either partially or fully outside the distribution of the five traits examined in 2.1 and compare it with the performance of our h-rlhf and hh-rlhf pms (see figure 15). the trait pm achieves reasonable success even for problematic behavioral traits beyond the five traits on which it was trained. for example, the trait pm detects and discourages expressions associ- ated with dark triad traits of