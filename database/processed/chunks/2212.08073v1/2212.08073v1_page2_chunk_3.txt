by eliminating evasive responses , reducing tension1[bai et al., 2022, glaese et al., 2022] between helpfulness and harmlessness and encouraging the ai to explain its objections to harmful requests, (3) to make the principles governing ai behavior, and their implementation, more transparent, and (4) to reduce iteration time by obviating the need to collect new human feedback labels when altering the objective. let us discuss these motivations in more detail. 1.1 motivations scaling supervision we use the term scaling supervision for techniques that leverage ai to help humans to more efciently supervise ai, making it possible to train systems to behave in desirable ways (e.g. to be helpful, honest, and 1that is, helpfulness tends to increase harmfulness, since models are willing to obey pernicious requests, and con- versely models trained to be harmless tend to be more evasive and generally less helpful. by harmfulness we in- clude both a variety of forms of harm to the user and responses that help the user to achieve harmful aims. see [bai et al., 2022, ganguli et al., 2022] for more discussion of our operational denitions of helpful and harmless. 2