red teamers to engage in the rather unsavory work of trying to trick ai systems into generating harmful content. 7 contribution statement model pre-training: model pretraining was led by nicholas joseph and sam mccandlish, with help from tom brown and jared kaplan, and much of anthropics technical staff contributed to the development of our efcient distributed training infrastructure and the underlying machine learning systems. core contributors include tom henighan, scott johnston, sheer el showk, nelson elhage, and ben mann. scott johnston in particular worked on optimizing pretraining for ml efciency, while sheer el showk, carol chen, and jennifer zhou worked on data. reinforcement learning: the core rl infrastructure was built by andy jones and kamal ndousse in collaboration with shauna kravec and dawn drain. development of the rl infrastructure has been led by sam mccandlish and dario amodei. sampling and evaluation: efcient sampling efforts were led by tom brown, and tom conerly carried out major aspects of the design, implementation and support for the system, with help from zac hateld- dodds. many members of anthropic worked on our framework for evaluations, including saurav kadavath, nicholas schiefer, nick joseph, tom henighan, amanda askell, jared kaplan, andy jones, ethan perez, scott johnston, and sam mccandlish. saurav in particular developed the systems for efcient composition of sampling, prompting, and evaluation used for sl and rl cai, which were one of the primary tools used in this project. jackson kernion helped support human feedback data collection. cluster: nova dassarma and eli tran-johnson managed the research cluster our research depended on and maintained its stability, making this research possible. many others helped with these efforts, including ben mann, tom henighan, sam mccandlish, andy jones, zac hateld-dodds, and tristan hume. research: jared kaplan developed the main ideas in discussion with yuntao bai, amanda askell, and saurav