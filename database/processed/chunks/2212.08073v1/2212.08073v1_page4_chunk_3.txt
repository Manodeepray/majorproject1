training ai assistants that explain why they are declining to engage with harmful requests. 3with our present methods, this should possible by training ai systems to imitate the natural language explanations hu- mans give when evaluating ai behavior, as has been discussed in other contexts [scheurer et al., , saunders et al., 2022], but leave this to future work. 4in some contexts this could be a virtue [xu et al., 2020], but in this paper we view it as a problem since it reduces transparency and helpfulness. 4