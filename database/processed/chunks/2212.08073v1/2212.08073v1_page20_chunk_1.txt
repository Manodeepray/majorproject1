1091010 parameters0.40.50.60.70.8accuracy previous hhh comparison evals hh pm from human feedback helpful rlhf (0-shot) helpful rlhf (5-shot) chancefigure 11 results on the original hhh evaluations developed in [askell et al., 2021] and available on big bench [srivastava et al., 2022]. 1091010 parameters0.500.550.600.650.70accuracy identify harmful vs ethical assistant behavior pretrained lm (5-shot) helpful rlhf (0-shot) helpful rlhf (5-shot) chain-of-thought (prompted) chance 1091010 parameters0.10.20.30.40.50.6accuracy classifying harmful behavior pretrained lm (5-shot) helpful rlhf (0-shot) helpful rlhf (5-shot) chance figure 12 here we show results on identifying and classifying harmful behaviors, without any task specic training or human feedback. (left) we show model accuracy at identifying harmful versus ethical ai assistant behavior. (right) we show results classifying a harmful interaction using one of nine common labels. have made this task a bit more challenging for small models or zero-shot evaluation. we show results on this evaluation on the left in figure 12. chain-of-thought and few-shot evaluation signicantly improve the zero-shot performance. for the task of classifying harmful behavior, we used the nine most frequently occurring labels assigned by crowdworkers to red teaming conversations, and constructed a dataset of 287 examples. we then constructed 9-way multiple choice problems for our ai models. the accuracy can be seen on the right in figure 12. these results suggest that as model capabilities continue to improve, it should become increasingly tractable to use ai evaluations to identify and avoid harmful behaviors. c constitutional principles used for this research here we show the constitutional principles and instructions we used for sl-cai and rl-cai. these were selected in a fairly ad hoc manner for research purposes. c.1 principles for sl-cai critiquerequest: identify specific ways in which the assistants last response is harmful, unethical, racist, sexist, toxic, dangerous, or illegal. revisionrequest: please rewrite the assistant response to remove any and all