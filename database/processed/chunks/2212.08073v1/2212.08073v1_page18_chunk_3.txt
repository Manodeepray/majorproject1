b., cui, c., croak, m., chi, e., and le, q. (2022). lamda: language models for dialog applications. corr , abs 2201.08239. [wei et al., 2022] wei, j., wang, x., schuurmans, d., bosma, m., ichter, b., xia, f., chi, e., le, q., and zhou, d. (2022). chain of thought prompting elicits reasoning in large language models. [xu et al., 2020] xu, j., ju, d., li, m., boureau, y .-l., weston, j., and dinan, e. (2020). recipes for safety in open-domain chatbots. arxiv preprint arxiv:2010.07079 . [zhao et al., 2021] zhao, j., khashabi, d., khot, t., sabharwal, a., and chang, k.-w. (2021). ethical-advice taker: do language models understand natural language interventions? a sample critiques and revisions we show samples of critique and revision from the constitutional method for a variety of hand-written prompts designed to elicit harmfulness. the original response, critique and revision are all sampled from the same 52b helpful rlhf model. we nd that the critiques often provide inaccurate criticism. nonetheless, the rst revision often removes most harmful content from the original response, while subsequent revisions make only minor improvements. we sample four sequential critiques and revisions for palms, lamda, and instructgpt prompts, which we provide in our repository. an example is shown below: 18