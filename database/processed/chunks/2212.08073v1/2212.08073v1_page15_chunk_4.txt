remaining issue, and a major motivation for this work, is robustness that is, can we make models essentially immune to red-team attacks? we hope that by making helpfulness and harmlessness more com- patible, we will be able to signicantly scale-up (automated) red teaming in order to improve robustness. furthermore, we should be able to perform iterated online training [bai et al., 2022] with ai supervision, 15