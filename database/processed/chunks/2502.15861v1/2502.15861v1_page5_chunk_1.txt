c3ai: crafting and evaluating constitutions for constitutional ai www 25, april 28-may 2, 2025, sydney, nsw, australia external human input, reducing the influence of researcher biases and staying true to the original items. 4.3 principle selection we have implemented three data-driven approaches for selecting principles, which can be used independently or in combination. first, principle-objective alignment (4.3.1) assesses how well dif- ferent principles align with human preferences to achieve specific conversational objectives, identifying which principles resonate most with real-world users. second, framing analysis (4.3.2) in- vestigates the impact of principle framing (e.g., positive vs.negative framing) on obtaining responses aligned with human preferences. third, the psychometrics approach (4.3.3), leveraging exploratory graph analysis (ega) and unique variable analysis (uva), refines the selection process by identifying stable and meaningful prin- ciples while reducing redundancy, ensuring a more concise and effective set of principles for constitutions. 4.3.1 approach 1: principle-objective alignment. to systematically assess how different principles align with various conversational ob- jectives, we identified three key objectives first - ensuring that con- versations are harmless, helpful, and effective in general-purpose contexts - and we then analyzed how responses chosen by an llm, guided by these principles, aligned with those preferred by individ- uals with corresponding conversational objectives. to that end, we randomly sampled 300 single-turn conversations for each of our five human preference datasets, plus 300 extra for prism due to its multiple conversational objectives ( 1,800conver- sations in total). we then used 185 principles described in 4.2 to generate 333,000principle-objective alignment values (whether a response chosen based on a principle aligns with a response chosen by humans based on a conversational objective). that is, we measured principle-objective alignment by instructing an llm evaluator (llama-3-8b) to choose between two responses to a users query based on a given principle, using a 3-shot prompt