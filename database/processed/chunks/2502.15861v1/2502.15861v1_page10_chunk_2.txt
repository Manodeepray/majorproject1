michael terry. 2024. constitution- maker: interactively critiquing large language models by converting feedback into principles. in proceedings of the international conference on intelligent user interfaces (iui) . 853868. [55] zhen qin, rolf jagerman, kai hui, honglei zhuang, junru wu, le yan, jiaming shen, tianqi liu, jialu liu, donald metzler, et al .2023. large language models are effective text rankers with pairwise ranking prompting. arxiv:2306.17563 (2023). [56] rafael rafailov, archit sharma, eric mitchell, christopher d. manning, stefano ermon, and chelsea finn. 2024. direct preference optimization: your language model is secretly a reward model. advances in neural information processing systems 36 (2024). [57] malak sadek, marios constantinides, daniele quercia, and celine mougenot. 2024. guidelines for integrating value sensitive design in responsible ai toolkits. inproceedings of the conference on human factors in computing systems (chi) . association for computing machinery, article 472, 20 pages. doi:10.1145 3613904. 3642810 [58] christoph salge and daniel polani. 2017. empowerment as replacement for the three laws of robotics. frontiers in robotics and ai (2017). doi:10.3389 frobt. 2017.00025 [59] shibani santurkar, esin durmus, faisal ladhak, cinoo lee, percy liang, and tatsunori hashimoto. 2023. whose opinions do language models reflect?. in international conference on machine learning (icml) . 2997130004. [60] shalom h schwartz. 1992. universals in the content and structure of values: the- oretical advances and empirical tests in 20 countries. advances in experimental social psychology academic press (1992). [61] shalom h. schwartz and jan cieciuch. 2022. measuring the refined theory of individual values in 49 cultural groups: psychometrics of the revised portrait value questionnaire. assessment 29, 5 (2022), 10051019.[62] hua shen, tiffany knearem, reshmi ghosh, kenan alkiek, kundan krishna, yachuan liu, ziqiao ma, savvas petridis, yi-hao peng, li qiwei, et al .2024. to- wards bidirectional human-ai alignment: a systematic review for clarifications, framework, and future directions. arxiv:2406.09264 (2024). [63]