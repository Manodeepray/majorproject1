stereotypes [ 1,37], and making unsafe or illicit suggestions [ 19,29, 63]. since potential harms are diverse, gabriel [27]suggests that it is most reasonable to align ai agents with human values - as opposed to, for instance, having explicit instructions or implicit preferences - such that the agents actions are guided by a notion of morality or what it should and should not do, as defined by humans either individually or collectively. an established psychological theory of