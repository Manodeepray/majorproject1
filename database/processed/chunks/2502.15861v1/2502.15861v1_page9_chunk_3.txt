(2024). [16] karl cobbe, vineet kosaraju, mohammad bavarian, mark chen, heewoo jun, lukasz kaiser, matthias plappert, jerry tworek, jacob hilton, reiichiro nakano, christopher hesse, and john schulman. 2021. training verifiers to solve math word problems. arxiv abs 2110.14168 (2021). [url] corpusid:239998651 [17] vincent conitzer, rachel freedman, jobst heitzig, wesley h holliday, bob m ja- cobs, nathan lambert, milan moss, eric pacuit, stuart russell, hailey schoelkopf, et al.2024. social choice should guide ai alignment in dealing with diverse hu- man feedback. in proceedings of the international conference on machine learning (icml) . [18] chunyuan deng, yilun zhao, xiangru tang, mark gerstein, and arman co- han. 2023. investigating data contamination in modern benchmarks for large language models. arxiv:2311.09783 (2023). [19] ameet deshpande, vishvak murahari, tanmay rajpurohit, ashwin kalyan, and karthik narasimhan. 2023. toxicity in chatgpt: analyzing persona-assigned language models. arxiv:2304.05335 (2023). [20] robert f devellis. 2006. classical test theory. medical care 44, 11 (2006), s50s59. [21] esin durmus, karina nguyen, thomas i liao, nicholas schiefer, amanda askell, anton bakhtin, carol chen, zac hatfield-dodds, danny hernandez, nicholas joseph, et al .2023. towards measuring the representation of subjective global opinions in language models. arxiv:2306.16388 (2023). [22] susan e. embretson and steven p. reise. 2013. item response theory . psychology press. [23] kawin ethayarajh, yejin choi, and swabha swayamdipta. 2022. understand- ing dataset difficulty with usable information. in international conference on machine learning (icml) . pmlr, 59886008. [24] barbara j. evans. 2023. rules for robots, and why medical ai breaks them. journal of law and the biosciences 10, 1 (02 2023), lsad001. doi:10.1093 jlb lsad001 arxiv:[url] pdf 10 1 lsad001 49225082 lsad001.pdf[25] leandre r. fabrigar and duane t. wegener. 2012. exploratory factor analysis . oxford university press. [26] arduin findeis, timo kaufmann, eyke hllermeier, samuel albanie, and robert mullins. 2024. inverse constitutional ai: compressing preferences