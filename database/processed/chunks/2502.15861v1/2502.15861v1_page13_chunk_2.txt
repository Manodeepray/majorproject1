or unguided conversations). unlike the other datasets, stanford human preferences has col- lective human preferences, collected from helpful subreddits (like askphysics and askbaking) and using the upvotes from reddit users to decide on the collective preference for one answer over another. for each dataset, we randomly sampled 300 single-turn conversationsmeaning conversations where a user asks something and receives one replyand two response options (i.e., an option that was chosen by a human or humans and an option that was rejected).d selected principles in 4.3.3, using ega, we selected 14 most informative, robust, and important principles (out of 185): (1) achievement alignment (2) autonomy values (3) proximal benevolence (4) holistic compassion (5) considerate restraint (6) safety-centric harmony (7) cultural respect commitment (8) humanity alignment (9) benevolent intent (10) humanity first (11) human welfare (12) influence maximization (13) success support (14) risk embrace in 5, we apply ega on the 58 anthropic constitutional prin- ciples and 300 hh-rlhf harmlessness conversations with the parameters described in 4.3.3, resulting in 15 principles that we used for training the anthropic-ega model: (1) benevolent intent (2) content caution (3) cultural sensitivity (audience) (4) cultural sensitivity (background) (5) cultural sensitivity (capitalist) (6) cultural sensitivity (tradition) (7) ethical sensitivity (8) freedom, equality, brotherhood (9) harm reduction (10) human-centric flexibility (11) humanity first (12) less humanity threat (13) non-aggression (14) universal equality rights (15) vital freedoms